{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b3c18af-27ca-4259-a9f7-63d4e646504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import ast\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import trapezoid\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c74be9e-33ed-46db-86a1-229f4c5de21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PTB-XL database...\n",
      "Loaded 21837 ECG records from database\n",
      "Database columns: ['ecg_id', 'patient_id', 'age', 'sex', 'height', 'weight', 'nurse', 'site', 'device', 'recording_date', 'report', 'scp_codes', 'heart_axis', 'infarction_stadium1', 'infarction_stadium2', 'validated_by', 'second_opinion', 'initial_autogenerated_report', 'validated_by_human', 'baseline_drift', 'static_noise', 'burst_noise', 'electrodes_problems', 'extra_beats', 'pacemaker', 'strat_fold', 'filename_lr', 'filename_hr']\n",
      "\n",
      "Sample metadata:\n",
      "   ecg_id  patient_id   age  sex  height  weight  nurse  site     device  \\\n",
      "0       1     15709.0  56.0    1     NaN    63.0    2.0   0.0  CS-12   E   \n",
      "1       2     13243.0  19.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
      "2       3     20372.0  37.0    1     NaN    69.0    2.0   0.0  CS-12   E   \n",
      "3       4     17014.0  24.0    0     NaN    82.0    2.0   0.0  CS-12   E   \n",
      "4       5     17448.0  19.0    1     NaN    70.0    2.0   0.0  CS-12   E   \n",
      "\n",
      "        recording_date  ... validated_by_human  baseline_drift static_noise  \\\n",
      "0  1984-11-09 09:17:34  ...               True             NaN    , I-V1,     \n",
      "1  1984-11-14 12:55:37  ...               True             NaN          NaN   \n",
      "2  1984-11-15 12:49:10  ...               True             NaN          NaN   \n",
      "3  1984-11-15 13:44:57  ...               True    , II,III,AVF          NaN   \n",
      "4  1984-11-17 10:43:15  ...               True   , III,AVR,AVF          NaN   \n",
      "\n",
      "  burst_noise electrodes_problems  extra_beats  pacemaker  strat_fold  \\\n",
      "0         NaN                 NaN          NaN        NaN           3   \n",
      "1         NaN                 NaN          NaN        NaN           2   \n",
      "2         NaN                 NaN          NaN        NaN           5   \n",
      "3         NaN                 NaN          NaN        NaN           3   \n",
      "4         NaN                 NaN          NaN        NaN           4   \n",
      "\n",
      "                 filename_lr                filename_hr  \n",
      "0  records100/00000/00001_lr  records500/00000/00001_hr  \n",
      "1  records100/00000/00002_lr  records500/00000/00002_hr  \n",
      "2  records100/00000/00003_lr  records500/00000/00003_hr  \n",
      "3  records100/00000/00004_lr  records500/00000/00004_hr  \n",
      "4  records100/00000/00005_lr  records500/00000/00005_hr  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "BASE = r\"C:\\Users\\iamsn\\ECG Classifier\\ECG Classifier\"\n",
    "TARGET_FS = 100  \n",
    "\n",
    "\n",
    "if not os.path.exists(BASE):\n",
    "    raise FileNotFoundError(f\"Base directory not found: {BASE}\")\n",
    "    \n",
    "csv_path = os.path.join(BASE, \"ptbxl_database.csv\")\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Database CSV not found: {csv_path}\")\n",
    "\n",
    "\n",
    "print(\"Loading PTB-XL database...\")\n",
    "df_meta = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df_meta)} ECG records from database\")\n",
    "print(f\"Database columns: {list(df_meta.columns)}\")\n",
    "\n",
    "\n",
    "print(f\"\\nSample metadata:\")\n",
    "print(df_meta.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65cc92ea-0db7-424a-87a9-4cd6ae6f8ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data availability...\n",
      "Checking availability of first 1000 ECG files...\n",
      "  Checked 0/1000 files...\n",
      "  Checked 200/1000 files...\n",
      "  Checked 400/1000 files...\n",
      "  Checked 600/1000 files...\n",
      "  Checked 800/1000 files...\n",
      "\n",
      " Data Availability Summary:\n",
      "Available files: 30\n",
      "Missing files: 970\n",
      "Availability rate: 3.0%\n",
      "Warning: Only 30 files available. This may not be sufficient for training.\n",
      "\n",
      " Will process 30 available ECG records\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing data availability...\")\n",
    "available_files = []\n",
    "missing_files = []\n",
    "\n",
    "\n",
    "sample_ids = df_meta.ecg_id.values[:1000]\n",
    "print(f\"Checking availability of first {len(sample_ids)} ECG files...\")\n",
    "\n",
    "for i, ecg_id in enumerate(sample_ids):\n",
    "    if i % 200 == 0:  # Progress indicator\n",
    "        print(f\"  Checked {i}/{len(sample_ids)} files...\")\n",
    "    \n",
    "    row = df_meta[df_meta.ecg_id == ecg_id].iloc[0]\n",
    "    rec_path = os.path.join(BASE, row.filename_lr)\n",
    "    \n",
    "    if os.path.exists(rec_path + '.hea') and os.path.exists(rec_path + '.dat'):\n",
    "        available_files.append(ecg_id)\n",
    "    else:\n",
    "        missing_files.append(ecg_id)\n",
    "\n",
    "print(f\"\\n Data Availability Summary:\")\n",
    "print(f\"Available files: {len(available_files)}\")\n",
    "print(f\"Missing files: {len(missing_files)}\")\n",
    "print(f\"Availability rate: {len(available_files)/len(sample_ids)*100:.1f}%\")\n",
    "if len(available_files) == 0:\n",
    "    raise RuntimeError(\"No ECG data files found! Please check your data directory.\")\n",
    "elif len(available_files) < 100:\n",
    "    print(f\"Warning: Only {len(available_files)} files available. This may not be sufficient for training.\")\n",
    "\n",
    "# Use only available files for processing\n",
    "df_meta_available = df_meta[df_meta.ecg_id.isin(available_files)]\n",
    "print(f\"\\n Will process {len(df_meta_available)} available ECG records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26bfe41d-5c35-4dcd-9f6f-33d7504589a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available ECG Records Summary:\n",
      "Shape: (30, 28)\n",
      "Columns: ['ecg_id', 'patient_id', 'age', 'sex', 'height', 'weight', 'nurse', 'site', 'device', 'recording_date', 'report', 'scp_codes', 'heart_axis', 'infarction_stadium1', 'infarction_stadium2', 'validated_by', 'second_opinion', 'initial_autogenerated_report', 'validated_by_human', 'baseline_drift', 'static_noise', 'burst_noise', 'electrodes_problems', 'extra_beats', 'pacemaker', 'strat_fold', 'filename_lr', 'filename_hr']\n",
      "\n",
      "First few available records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>...</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>baseline_drift</th>\n",
       "      <th>static_noise</th>\n",
       "      <th>burst_noise</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15709.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-09 09:17:34</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-V1,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13243.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-14 12:55:37</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20372.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 12:49:10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 13:44:57</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>, II,III,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-17 10:43:15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>, III,AVR,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ecg_id  patient_id   age  sex  height  weight  nurse  site     device  \\\n",
       "0       1     15709.0  56.0    1     NaN    63.0    2.0   0.0  CS-12   E   \n",
       "1       2     13243.0  19.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "2       3     20372.0  37.0    1     NaN    69.0    2.0   0.0  CS-12   E   \n",
       "3       4     17014.0  24.0    0     NaN    82.0    2.0   0.0  CS-12   E   \n",
       "4       5     17448.0  19.0    1     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "\n",
       "        recording_date  ... validated_by_human  baseline_drift static_noise  \\\n",
       "0  1984-11-09 09:17:34  ...               True             NaN    , I-V1,     \n",
       "1  1984-11-14 12:55:37  ...               True             NaN          NaN   \n",
       "2  1984-11-15 12:49:10  ...               True             NaN          NaN   \n",
       "3  1984-11-15 13:44:57  ...               True    , II,III,AVF          NaN   \n",
       "4  1984-11-17 10:43:15  ...               True   , III,AVR,AVF          NaN   \n",
       "\n",
       "  burst_noise electrodes_problems  extra_beats  pacemaker  strat_fold  \\\n",
       "0         NaN                 NaN          NaN        NaN           3   \n",
       "1         NaN                 NaN          NaN        NaN           2   \n",
       "2         NaN                 NaN          NaN        NaN           5   \n",
       "3         NaN                 NaN          NaN        NaN           3   \n",
       "4         NaN                 NaN          NaN        NaN           4   \n",
       "\n",
       "                 filename_lr                filename_hr  \n",
       "0  records100/00000/00001_lr  records500/00000/00001_hr  \n",
       "1  records100/00000/00002_lr  records500/00000/00002_hr  \n",
       "2  records100/00000/00003_lr  records500/00000/00003_hr  \n",
       "3  records100/00000/00004_lr  records500/00000/00004_hr  \n",
       "4  records100/00000/00005_lr  records500/00000/00005_hr  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Available ECG Records Summary:\")\n",
    "print(f\"Shape: {df_meta_available.shape}\")\n",
    "print(f\"Columns: {list(df_meta_available.columns)}\")\n",
    "print(\"\\nFirst few available records:\")\n",
    "df_meta_available.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe549a6b-ad66-4bc4-a1ce-8a71abeca8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# === ECG Data Loading Functions ===\n",
    "\n",
    "def load_and_normalize(ecg_id, df_source=None):\n",
    "    \"\"\"\n",
    "    Load and normalize ECG signal data.\n",
    "    \n",
    "    Args:\n",
    "        ecg_id: ECG record ID\n",
    "        df_source: Source dataframe (defaults to df_meta_available)\n",
    "    \n",
    "    Returns:\n",
    "        Normalized ECG signal array\n",
    "    \"\"\"\n",
    "    if df_source is None:\n",
    "        df_source = df_meta_available\n",
    "    \n",
    "    # Find the record\n",
    "    matching_rows = df_source[df_source.ecg_id == ecg_id]\n",
    "    if len(matching_rows) == 0:\n",
    "        raise ValueError(f\"ECG ID {ecg_id} not found in metadata\")\n",
    "    \n",
    "    row = matching_rows.iloc[0]\n",
    "    rec_path = os.path.join(BASE, row.filename_lr)\n",
    "    \n",
    "    # Validate files exist\n",
    "    if not os.path.exists(rec_path + '.hea'):\n",
    "        raise FileNotFoundError(f\"Header file not found: {rec_path}.hea\")\n",
    "    if not os.path.exists(rec_path + '.dat'):\n",
    "        raise FileNotFoundError(f\"Data file not found: {rec_path}.dat\")\n",
    "    try:\n",
    "        # Load ECG signal\n",
    "        sig, meta = wfdb.rdsamp(rec_path)\n",
    "        \n",
    "        # Validate sampling frequency\n",
    "        if meta['fs'] != TARGET_FS:\n",
    "            print(f\" Warning: Expected {TARGET_FS} Hz, got {meta['fs']} Hz for record {ecg_id}\")\n",
    "        \n",
    "        # Validate signal shape\n",
    "        if sig is None or len(sig) == 0:\n",
    "            raise ValueError(f\"Empty signal for record {ecg_id}\")\n",
    "        \n",
    "        if sig.shape[1] != 12:\n",
    "            print(f\" Warning: Expected 12 leads, got {sig.shape[1]} leads for record {ecg_id}\")\n",
    "        \n",
    "        # Normalize signal (per lead)\n",
    "        sig_norm = StandardScaler().fit_transform(sig)\n",
    "        \n",
    "        return sig_norm\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load ECG {ecg_id}: {str(e)}\")\n",
    "print(\"ECG loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a512670-378a-471e-934b-f6f4f3434b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "def extract_features_from_ecg(sig, fs=100):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from ECG signal.\n",
    "    \n",
    "    Args:\n",
    "        sig: ECG signal array (n_samples, n_leads)\n",
    "        fs: Sampling frequency\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of extracted features\n",
    "    \"\"\"\n",
    "    if sig is None or len(sig) == 0:\n",
    "        raise ValueError(\"Empty signal provided\")\n",
    "    \n",
    "    feat = {}\n",
    "    n_leads = sig.shape[1] if len(sig.shape) > 1 else 1\n",
    "    \n",
    "    # Ensure signal is 2D\n",
    "    if len(sig.shape) == 1:\n",
    "        sig = sig.reshape(-1, 1)\n",
    "        n_leads = 1\n",
    "    \n",
    "    for lead in range(n_leads):\n",
    "        s = sig[:, lead]\n",
    "        \n",
    "        # Handle potential NaN or infinite values\n",
    "        if np.any(np.isnan(s)) or np.any(np.isinf(s)):\n",
    "            print(f\"Warning: NaN or infinite values found in lead {lead}\")\n",
    "            s = np.nan_to_num(s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Time-domain statistical features\n",
    "        try:\n",
    "            feat[f'L{lead}_mean'] = np.mean(s)\n",
    "            feat[f'L{lead}_std'] = np.std(s)\n",
    "            feat[f'L{lead}_min'] = np.min(s)\n",
    "            feat[f'L{lead}_max'] = np.max(s)\n",
    "            feat[f'L{lead}_median'] = np.median(s)\n",
    "            feat[f'L{lead}_range'] = np.max(s) - np.min(s)\n",
    "            feat[f'L{lead}_skew'] = skew(s)\n",
    "            feat[f'L{lead}_kurtosis'] = kurtosis(s)\n",
    "            feat[f'L{lead}_rms'] = np.sqrt(np.mean(s**2))\n",
    "            \n",
    "            # Additional statistical features\n",
    "            feat[f'L{lead}_var'] = np.var(s)\n",
    "            feat[f'L{lead}_q25'] = np.percentile(s, 25)\n",
    "            feat[f'L{lead}_q75'] = np.percentile(s, 75)\n",
    "            feat[f'L{lead}_iqr'] = feat[f'L{lead}_q75'] - feat[f'L{lead}_q25']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Warning: Error computing time-domain features for lead {lead}: {e}\")\n",
    "            # Set default values\n",
    "            for feature_name in ['mean', 'std', 'min', 'max', 'median', 'range', 'skew', 'kurtosis', 'rms', 'var', 'q25', 'q75', 'iqr']:\n",
    "                feat[f'L{lead}_{feature_name}'] = 0.0\n",
    "        \n",
    "        # Frequency-domain features\n",
    "        try:\n",
    "            # Use appropriate nperseg based on signal length\n",
    "            nperseg = min(256, len(s) // 4)\n",
    "            if nperseg < 4:\n",
    "                nperseg = len(s)\n",
    "            \n",
    "            f, Pxx = welch(s, fs=fs, nperseg=nperseg)\n",
    "            \n",
    "            # Clinical frequency bands\n",
    "            mask_total = (f >= 0.5) & (f <= 40)\n",
    "            mask_low = (f >= 0.5) & (f <= 4)\n",
    "            mask_mid = (f >= 4) & (f <= 15)\n",
    "            mask_high = (f >= 15) & (f <= 40)\n",
    "            \n",
    "            if np.any(mask_total):\n",
    "                feat[f'L{lead}_bandpower_total'] = trapezoid(Pxx[mask_total], f[mask_total])\n",
    "                feat[f'L{lead}_dominant_freq'] = f[mask_total][np.argmax(Pxx[mask_total])]\n",
    "            else:\n",
    "                feat[f'L{lead}_bandpower_total'] = 0.0\n",
    "                feat[f'L{lead}_dominant_freq'] = 0.0\n",
    "            \n",
    "            # Band-specific power\n",
    "            for band_name, mask in [('low', mask_low), ('mid', mask_mid), ('high', mask_high)]:\n",
    "                if np.any(mask):\n",
    "                    feat[f'L{lead}_bandpower_{band_name}'] = trapezoid(Pxx[mask], f[mask])\n",
    "                else:\n",
    "                    feat[f'L{lead}_bandpower_{band_name}'] = 0.0\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error computing frequency-domain features for lead {lead}: {e}\")\n",
    "            # Set default values\n",
    "            for feature_name in ['bandpower_total', 'dominant_freq', 'bandpower_low', 'bandpower_mid', 'bandpower_high']:\n",
    "                feat[f'L{lead}_{feature_name}'] = 0.0\n",
    "    \n",
    "    return feat\n",
    "\n",
    "def validate_features(features_dict):\n",
    "    \"\"\"Validate extracted features for NaN or infinite values.\"\"\"\n",
    "    invalid_features = []\n",
    "    for key, value in features_dict.items():\n",
    "        if np.isnan(value) or np.isinf(value):\n",
    "            invalid_features.append(key)\n",
    "            features_dict[key] = 0.0  # Replace with default value\n",
    "    \n",
    "    if invalid_features:\n",
    "        print(f\"Replaced {len(invalid_features)} invalid feature values with 0.0\")\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "print(\"Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6068af4b-b79e-4f6a-a4da-1e1841b7e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing diagnostic labels (SCP codes)...\n",
      "Sample SCP codes (raw):\n",
      "  1: {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}\n",
      "  2: {'NORM': 80.0, 'SBRAD': 0.0}\n",
      "  3: {'NORM': 100.0, 'SR': 0.0}\n",
      "  4: {'NORM': 100.0, 'SR': 0.0}\n",
      "  5: {'NORM': 100.0, 'SR': 0.0}\n",
      "  6: {'NORM': 100.0, 'SR': 0.0}\n",
      "  7: {'NORM': 100.0, 'SR': 0.0}\n",
      "  8: {'IMI': 35.0, 'ABQRS': 0.0, 'SR': 0.0}\n",
      "  9: {'NORM': 100.0, 'SR': 0.0}\n",
      "  10: {'NORM': 100.0, 'SR': 0.0}\n",
      "  11: {'NORM': 80.0, 'SARRH': 0.0}\n",
      "  12: {'NORM': 80.0, 'SBRAD': 0.0}\n",
      "  13: {'NORM': 100.0, 'SR': 0.0}\n",
      "  14: {'NORM': 100.0, 'SR': 0.0}\n",
      "  15: {'NORM': 100.0, 'SARRH': 0.0}\n",
      "  16: {'NORM': 100.0, 'SR': 0.0}\n",
      "  17: {'AFLT': 100.0, 'ABQRS': 0.0, 'AFIB': 0.0}\n",
      "  18: {'AFLT': 100.0}\n",
      "  19: {'NORM': 100.0, 'SR': 0.0}\n",
      "  20: {'AFLT': 100.0, 'ABQRS': 0.0}\n",
      "\n",
      " Label Distribution:\n",
      "  Normal (NORM): 21 (70.0%)\n",
      "   Abnormal: 9 (30.0%)\n",
      "\n",
      "Most common abnormal codes:\n",
      "  SR: 5\n",
      "  AFLT: 4\n",
      "  ABQRS: 3\n",
      "  NST_: 2\n",
      "  DIG: 2\n",
      "  IMI: 1\n",
      "  AFIB: 1\n",
      "  NDT: 1\n",
      "  LVH: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing diagnostic labels (SCP codes)...\")\n",
    "\n",
    "# Convert SCP codes to proper format\n",
    "scp_codes_sample = df_meta_available['scp_codes'].head(20)\n",
    "print(\"Sample SCP codes (raw):\")\n",
    "for i, code in enumerate(scp_codes_sample):\n",
    "    print(f\"  {i+1}: {code}\")\n",
    "\n",
    "# Parse SCP codes and analyze distribution\n",
    "try:\n",
    "    df_meta_available_copy = df_meta_available.copy()\n",
    "    df_meta_available_copy['scp_codes_parsed'] = df_meta_available_copy['scp_codes'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Count normal vs abnormal\n",
    "    normal_count = 0\n",
    "    abnormal_count = 0\n",
    "    \n",
    "    for codes in df_meta_available_copy['scp_codes_parsed']:\n",
    "        if 'NORM' in codes:\n",
    "            normal_count += 1\n",
    "        else:\n",
    "            abnormal_count += 1\n",
    "    \n",
    "    print(f\"\\n Label Distribution:\")\n",
    "    print(f\"  Normal (NORM): {normal_count} ({normal_count/len(df_meta_available_copy)*100:.1f}%)\")\n",
    "    print(f\"   Abnormal: {abnormal_count} ({abnormal_count/len(df_meta_available_copy)*100:.1f}%)\")\n",
    "    \n",
    "    # Check class balance\n",
    "    if normal_count == 0 or abnormal_count == 0:\n",
    "        print(\"Warning: Severely imbalanced dataset - only one class present!\")\n",
    "    elif min(normal_count, abnormal_count) / max(normal_count, abnormal_count) < 0.1:\n",
    "        print(\"Warning: Highly imbalanced dataset - consider class weighting\")\n",
    "    \n",
    "    # Show most common abnormal codes\n",
    "    all_abnormal_codes = []\n",
    "    for codes in df_meta_available_copy['scp_codes_parsed']:\n",
    "        if 'NORM' not in codes:\n",
    "            all_abnormal_codes.extend(list(codes.keys()))\n",
    "    \n",
    "    if all_abnormal_codes:\n",
    "        from collections import Counter\n",
    "        common_codes = Counter(all_abnormal_codes).most_common(10)\n",
    "        print(f\"\\nMost common abnormal codes:\")\n",
    "        for code, count in common_codes:\n",
    "            print(f\"  {code}: {count}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error parsing SCP codes: {e}\")\n",
    "    print(\"Using fallback label analysis...\")\n",
    "    print(f\"Total available records: {len(df_meta_available)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2222c3c-7a1e-4495-8cac-34c31a86639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature extraction pipeline...\n",
      "Processing 30 ECG records...\n",
      "  Progress: 0/30 (0.0%)\n",
      "\n",
      " Feature Extraction Summary:\n",
      "  Successfully processed: 30\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "Warning: Only 30 records processed. This may not be sufficient for reliable ML training.\n",
      "\n",
      "Converting features to DataFrame...\n",
      "Feature matrix created:\n",
      "  Shape: (30, 216)\n",
      "  Features per record: 216\n",
      "  Memory usage: 0.0 MB\n",
      "\n",
      "Feature matrix validation:\n",
      "  NaN values: 0\n",
      "  Infinite values: 0\n",
      "\n",
      " Sample features (first 5 columns):\n",
      "             L0_mean  L0_std    L0_min    L0_max  L0_median\n",
      "ecg_id                                                     \n",
      "1      -1.705303e-16     1.0 -1.802458  6.461912  -0.096384\n",
      "2       9.237056e-17     1.0 -2.599301  4.992821  -0.305926\n",
      "3      -4.973799e-17     1.0 -1.330285  6.846310  -0.282427\n",
      "\n",
      " Feature statistics:\n",
      "            L0_mean        L0_std     L0_min     L0_max  L0_median\n",
      "count  3.000000e+01  3.000000e+01  30.000000  30.000000  30.000000\n",
      "mean  -2.469136e-17  1.000000e+00  -2.313966   5.415311  -0.206003\n",
      "std    8.214848e-17  7.456158e-16   0.874352   0.927771   0.079419\n",
      "min   -2.557954e-16  1.000000e+00  -4.361050   3.068567  -0.339188\n",
      "25%   -4.973799e-17  1.000000e+00  -2.945533   5.012279  -0.267125\n",
      "50%   -2.842171e-17  1.000000e+00  -2.170799   5.413832  -0.214059\n",
      "75%    1.421085e-17  1.000000e+00  -1.675719   6.278950  -0.141573\n",
      "max    1.989520e-16  1.000000e+00  -0.924453   6.846310  -0.025434\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting feature extraction pipeline...\")\n",
    "\n",
    "# Use only available ECG IDs and limit processing for efficiency\n",
    "max_samples = min(1000, len(df_meta_available))  # Process up to 1000 samples\n",
    "ecg_ids_to_process = df_meta_available.ecg_id.values[:max_samples]\n",
    "\n",
    "print(f\"Processing {len(ecg_ids_to_process)} ECG records...\")\n",
    "\n",
    "features_all = []\n",
    "successful_count = 0\n",
    "failed_count = 0\n",
    "error_summary = {}\n",
    "\n",
    "# Process ECGs with progress tracking\n",
    "for i, ecg_id in enumerate(ecg_ids_to_process):\n",
    "    # Progress indicator\n",
    "    if i % 100 == 0:\n",
    "        print(f\"  Progress: {i}/{len(ecg_ids_to_process)} ({i/len(ecg_ids_to_process)*100:.1f}%)\")\n",
    "        \n",
    "    try:\n",
    "        # Load and normalize ECG signal\n",
    "        sig = load_and_normalize(ecg_id, df_meta_available)\n",
    "        \n",
    "        # Extract features\n",
    "        feats = extract_features_from_ecg(sig, fs=TARGET_FS)\n",
    "        \n",
    "        # Validate features\n",
    "        feats = validate_features(feats)\n",
    "        \n",
    "        # Add metadata\n",
    "        feats['ecg_id'] = ecg_id\n",
    "        features_all.append(feats)\n",
    "        successful_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_count += 1\n",
    "        error_type = type(e).__name__\n",
    "        error_summary[error_type] = error_summary.get(error_type, 0) + 1\n",
    "        \n",
    "        # Print first few errors for debugging\n",
    "        if failed_count <= 5:\n",
    "            print(f\"Error processing {ecg_id}: {str(e)[:100]}...\")\n",
    "\n",
    "print(f\"\\n Feature Extraction Summary:\")\n",
    "print(f\"  Successfully processed: {successful_count}\")\n",
    "print(f\"  Failed: {failed_count}\")\n",
    "print(f\"  Success rate: {successful_count/(successful_count+failed_count)*100:.1f}%\")\n",
    "\n",
    "if error_summary:\n",
    "    print(f\"  Error breakdown:\")\n",
    "    for error_type, count in error_summary.items():\n",
    "        print(f\"    {error_type}: {count}\")\n",
    "\n",
    "# Validate we have enough data\n",
    "if successful_count == 0:\n",
    "    raise RuntimeError(\"No ECG records were successfully processed!\")\n",
    "elif successful_count < 50:\n",
    "    print(f\"Warning: Only {successful_count} records processed. This may not be sufficient for reliable ML training.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "print(\"\\nConverting features to DataFrame...\")\n",
    "features_df = pd.DataFrame(features_all).set_index('ecg_id')\n",
    "\n",
    "print(f\"Feature matrix created:\")\n",
    "print(f\"  Shape: {features_df.shape}\")\n",
    "print(f\"  Features per record: {features_df.shape[1]}\")\n",
    "print(f\"  Memory usage: {features_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Validate feature matrix\n",
    "print(f\"\\nFeature matrix validation:\")\n",
    "nan_count = features_df.isnull().sum().sum()\n",
    "inf_count = np.isinf(features_df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"  NaN values: {nan_count}\")\n",
    "print(f\"  Infinite values: {inf_count}\")\n",
    "\n",
    "if nan_count > 0:\n",
    "    print(\"Warning: NaN values found - replacing with 0\")\n",
    "    features_df = features_df.fillna(0)\n",
    "\n",
    "if inf_count > 0:\n",
    "    print(\"Warning: Infinite values found - replacing with 0\")\n",
    "    features_df = features_df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Preview features\n",
    "print(f\"\\n Sample features (first 5 columns):\")\n",
    "print(features_df.iloc[:3, :5])\n",
    "\n",
    "print(f\"\\n Feature statistics:\")\n",
    "print(features_df.describe().iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1254f9ff-767b-4021-9305-bd3eac9087ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed feature analysis:\n",
      "Total features extracted: 216\n",
      "\n",
      "Feature breakdown by type:\n",
      "  Statistical: 48 features\n",
      "  Other: 108 features\n",
      "  Frequency: 60 features\n",
      "\n",
      " No constant features found\n",
      "\n",
      "Sample feature correlations (first 10 features):\n",
      "           L0_mean  L0_std  L0_min  L0_max  L0_median\n",
      "L0_mean      1.000  -0.403  -0.432  -0.413      0.208\n",
      "L0_std      -0.403   1.000   0.434   0.231     -0.251\n",
      "L0_min      -0.432   0.434   1.000   0.785     -0.436\n",
      "L0_max      -0.413   0.231   0.785   1.000     -0.274\n",
      "L0_median    0.208  -0.251  -0.436  -0.274      1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed feature analysis:\")\n",
    "print(f\"Total features extracted: {len(features_df.columns)}\")\n",
    "\n",
    "# Group features by type\n",
    "feature_types = {}\n",
    "for col in features_df.columns:\n",
    "    if '_mean' in col or '_std' in col or '_min' in col or '_max' in col:\n",
    "        feature_types.setdefault('Statistical', []).append(col)\n",
    "    elif '_bandpower' in col or '_freq' in col:\n",
    "        feature_types.setdefault('Frequency', []).append(col)\n",
    "    else:\n",
    "        feature_types.setdefault('Other', []).append(col)\n",
    "\n",
    "print(\"\\nFeature breakdown by type:\")\n",
    "for ftype, features in feature_types.items():\n",
    "    print(f\"  {ftype}: {len(features)} features\")\n",
    "\n",
    "# Check for constant features (no variation)\n",
    "constant_features = []\n",
    "for col in features_df.select_dtypes(include=[np.number]).columns:\n",
    "    if features_df[col].nunique() <= 1:\n",
    "        constant_features.append(col)\n",
    "\n",
    "if constant_features:\n",
    "    print(f\"\\n Warning: Found {len(constant_features)} constant features that should be removed:\")\n",
    "    for feat in constant_features[:5]:  # Show first 5\n",
    "        print(f\"    {feat}\")\n",
    "    if len(constant_features) > 5:\n",
    "        print(f\"    ... and {len(constant_features)-5} more\")\n",
    "else:\n",
    "    print(\"\\n No constant features found\")\n",
    "\n",
    "# Show feature correlation (sample)\n",
    "if len(features_df.columns) > 1:\n",
    "    sample_corr = features_df.iloc[:, :10].corr()\n",
    "    print(f\"\\nSample feature correlations (first 10 features):\")\n",
    "    print(sample_corr.iloc[:5, :5].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f174aa52-22e9-4094-ad9a-3e7f243a2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing labels for machine learning...\n",
      "Matching metadata to 30 processed ECG records...\n",
      "Matched 30 metadata records to feature matrix\n",
      "Parsing SCP diagnostic codes...\n",
      "Successfully parsed SCP codes\n",
      "Sample SCP codes structure: {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}\n",
      "SCP codes type: <class 'dict'>\n",
      "\n",
      "Processed metadata shape: (30, 28)\n",
      "Available columns: ['patient_id', 'age', 'sex', 'height', 'weight', 'nurse', 'site', 'device', 'recording_date', 'report', 'scp_codes', 'heart_axis', 'infarction_stadium1', 'infarction_stadium2', 'validated_by', 'second_opinion', 'initial_autogenerated_report', 'validated_by_human', 'baseline_drift', 'static_noise', 'burst_noise', 'electrodes_problems', 'extra_beats', 'pacemaker', 'strat_fold', 'filename_lr', 'filename_hr', 'scp_codes_parsed']\n"
     ]
    }
   ],
   "source": [
    "# === Label Preparation ===\n",
    "\n",
    "print(\"Preparing labels for machine learning...\")\n",
    "\n",
    "# Filter metadata to match processed ECG records\n",
    "print(f\"Matching metadata to {len(features_df)} processed ECG records...\")\n",
    "df_meta_filtered = df_meta_available[df_meta_available.ecg_id.isin(features_df.index)].copy()\n",
    "df_meta_filtered = df_meta_filtered.set_index('ecg_id').loc[features_df.index]\n",
    "\n",
    "print(f\"Matched {len(df_meta_filtered)} metadata records to feature matrix\")\n",
    "\n",
    "# Validate metadata alignment\n",
    "if len(df_meta_filtered) != len(features_df):\n",
    "    print(f\"Warning: Metadata count ({len(df_meta_filtered)}) != Feature count ({len(features_df)})\")\n",
    "\n",
    "# Convert scp_codes from string to actual dict (safe eval)\n",
    "print(\"Parsing SCP diagnostic codes...\")\n",
    "try:\n",
    "    df_meta_filtered['scp_codes_parsed'] = df_meta_filtered['scp_codes'].apply(ast.literal_eval)\n",
    "    print(\"Successfully parsed SCP codes\")\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing SCP codes: {e}\")\n",
    "    # Fallback: create dummy labels if parsing fails\n",
    "    print(\"Creating fallback labels...\")\n",
    "    df_meta_filtered['scp_codes_parsed'] = [{'UNKNOWN': 1.0}] * len(df_meta_filtered)\n",
    "\n",
    "# Validate SCP codes structure\n",
    "sample_codes = df_meta_filtered['scp_codes_parsed'].iloc[0]\n",
    "print(f\"Sample SCP codes structure: {sample_codes}\")\n",
    "print(f\"SCP codes type: {type(sample_codes)}\")\n",
    "\n",
    "print(f\"\\nProcessed metadata shape: {df_meta_filtered.shape}\")\n",
    "print(f\"Available columns: {list(df_meta_filtered.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13b5ec0b-fd9f-4f2f-8c4d-67cd953897c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Metadata Summary:\n",
      "Shape: (30, 28)\n",
      "Index type: <class 'pandas.core.indexes.base.Index'>\n",
      "Index name: ecg_id\n",
      "\n",
      "First 3 records:\n",
      "         age  sex                          scp_codes_parsed\n",
      "ecg_id                                                     \n",
      "1       56.0    1  {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}\n",
      "2       19.0    0              {'NORM': 80.0, 'SBRAD': 0.0}\n",
      "3       37.0    1                {'NORM': 100.0, 'SR': 0.0}\n",
      "\n",
      "Index alignment check:\n",
      "Features index sample: [1, 2, 3, 4, 5]\n",
      "Metadata index sample: [1, 2, 3, 4, 5]\n",
      "Matching indices: 30/30\n"
     ]
    }
   ],
   "source": [
    "# Display filtered metadata summary\n",
    "print(\"Filtered Metadata Summary:\")\n",
    "print(f\"Shape: {df_meta_filtered.shape}\")\n",
    "print(f\"Index type: {type(df_meta_filtered.index)}\")\n",
    "print(f\"Index name: {df_meta_filtered.index.name}\")\n",
    "\n",
    "# Show first few records\n",
    "print(f\"\\nFirst 3 records:\")\n",
    "display_cols = ['age', 'sex', 'scp_codes_parsed'] if 'scp_codes_parsed' in df_meta_filtered.columns else df_meta_filtered.columns[:3]\n",
    "print(df_meta_filtered[display_cols].head(3))\n",
    "\n",
    "# Verify index alignment with features\n",
    "print(f\"\\nIndex alignment check:\")\n",
    "print(f\"Features index sample: {list(features_df.index[:5])}\")\n",
    "print(f\"Metadata index sample: {list(df_meta_filtered.index[:5])}\")\n",
    "index_match = len(set(features_df.index) & set(df_meta_filtered.index))\n",
    "print(f\"Matching indices: {index_match}/{len(features_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acbe444e-7b81-4aa3-a6c9-cb3e81fa28cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating binary classification labels (Normal vs Abnormal)...\n",
      "Labels created successfully\n",
      "Label distribution:\n",
      "  0 (Normal): 21 (70.0%)\n",
      "  1 (Abnormal): 9 (30.0%)\n",
      "Reasonable class balance (ratio: 0.429)\n",
      "\n",
      "Final dataset shape: (30, 217)\n",
      "Features: 216\n",
      "Samples: 30\n"
     ]
    }
   ],
   "source": [
    "# === Label Creation ===\n",
    "\n",
    "print(\"Creating binary classification labels (Normal vs Abnormal)...\")\n",
    "\n",
    "# Create labels based on SCP codes\n",
    "def create_label(scp_codes):\n",
    "    \"\"\"Convert SCP codes to binary label: 0=Normal, 1=Abnormal\"\"\"\n",
    "    try:\n",
    "        if isinstance(scp_codes, str):\n",
    "            # If still string, try to parse\n",
    "            scp_codes = ast.literal_eval(scp_codes)\n",
    "        \n",
    "        if isinstance(scp_codes, dict):\n",
    "            # Check if NORM is present\n",
    "            return 0 if 'NORM' in scp_codes else 1\n",
    "        else:\n",
    "            # Fallback for unexpected format\n",
    "            print(f\"Unexpected SCP code format: {type(scp_codes)}\")\n",
    "            return 1  # Default to abnormal\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing SCP codes: {e}\")\n",
    "        return 1  # Default to abnormal if error\n",
    "\n",
    "# Apply label creation\n",
    "if 'scp_codes_parsed' in df_meta_filtered.columns:\n",
    "    labels = df_meta_filtered['scp_codes_parsed'].apply(create_label)\n",
    "else:\n",
    "    # Fallback to original scp_codes column\n",
    "    labels = df_meta_filtered['scp_codes'].apply(create_label)\n",
    "\n",
    "# Add labels to features dataframe\n",
    "features_df = features_df.copy()  # Ensure we can modify\n",
    "features_df['label'] = labels\n",
    "\n",
    "# Validate label creation\n",
    "print(f\"Labels created successfully\")\n",
    "print(f\"Label distribution:\")\n",
    "label_counts = features_df['label'].value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    label_name = \"Normal\" if label == 0 else \"Abnormal\"\n",
    "    percentage = count / len(features_df) * 100\n",
    "    print(f\"  {label} ({label_name}): {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Check for missing labels\n",
    "missing_labels = features_df['label'].isnull().sum()\n",
    "if missing_labels > 0:\n",
    "    print(f\"Warning: {missing_labels} records have missing labels\")\n",
    "    features_df['label'] = features_df['label'].fillna(1)  # Default to abnormal\n",
    "\n",
    "# Class balance analysis\n",
    "if len(label_counts) == 2:\n",
    "    minority_class = label_counts.min()\n",
    "    majority_class = label_counts.max()\n",
    "    imbalance_ratio = minority_class / majority_class\n",
    "    \n",
    "    if imbalance_ratio < 0.1:\n",
    "        print(f\"Severe class imbalance detected (ratio: {imbalance_ratio:.3f})\")\n",
    "        print(f\"Consider using class weights or sampling techniques\")\n",
    "    elif imbalance_ratio < 0.3:\n",
    "        print(f\"Moderate class imbalance detected (ratio: {imbalance_ratio:.3f})\")\n",
    "    else:\n",
    "        print(f\"Reasonable class balance (ratio: {imbalance_ratio:.3f})\")\n",
    "else:\n",
    "    print(f\"Unexpected number of classes: {len(label_counts)}\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {features_df.shape}\")\n",
    "print(f\"Features: {features_df.shape[1] - 1}\")  # Subtract 1 for label column\n",
    "print(f\"Samples: {features_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17aa27ce-4f5e-4cec-acc3-984602e011ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Analysis:\n",
      "Label column type: int64\n",
      "Unique labels: [np.int64(0), np.int64(1)]\n",
      "Label statistics:\n",
      "count    30.000000\n",
      "mean      0.300000\n",
      "std       0.466092\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       1.000000\n",
      "max       1.000000\n",
      "Name: label, dtype: float64\n",
      "\n",
      "First 10 labels:\n",
      "  ECG 1: 0 (Normal)\n",
      "  ECG 2: 0 (Normal)\n",
      "  ECG 3: 0 (Normal)\n",
      "  ECG 4: 0 (Normal)\n",
      "  ECG 5: 0 (Normal)\n",
      "  ECG 6: 0 (Normal)\n",
      "  ECG 7: 0 (Normal)\n",
      "  ECG 8: 1 (Abnormal)\n",
      "  ECG 9: 0 (Normal)\n",
      "  ECG 10: 0 (Normal)\n",
      "\n",
      "Label validation:\n",
      "Missing labels: 0\n",
      "Invalid labels (not 0 or 1): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Label Analysis:\")\n",
    "print(f\"Label column type: {features_df['label'].dtype}\")\n",
    "print(f\"Unique labels: {sorted(features_df['label'].unique())}\")\n",
    "print(f\"Label statistics:\")\n",
    "print(features_df['label'].describe())\n",
    "\n",
    "print(f\"\\nFirst 10 labels:\")\n",
    "for i, (idx, label) in enumerate(features_df['label'].head(10).items()):\n",
    "    label_name = \"Normal\" if label == 0 else \"Abnormal\"\n",
    "    print(f\"  ECG {idx}: {label} ({label_name})\")\n",
    "\n",
    "# Verify no missing labels\n",
    "print(f\"\\nLabel validation:\")\n",
    "print(f\"Missing labels: {features_df['label'].isnull().sum()}\")\n",
    "print(f\"Invalid labels (not 0 or 1): {(~features_df['label'].isin([0, 1])).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa92eef6-6239-43b3-948d-9788bcfb9599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Dataset Summary:\n",
      "Shape: (30, 217)\n",
      "Features: 216 (excluding label)\n",
      "Samples: 30\n",
      "Memory: 0.0 MB\n",
      "\n",
      " Feature columns (first 10):\n",
      "   1. L0_mean\n",
      "   2. L0_std\n",
      "   3. L0_min\n",
      "   4. L0_max\n",
      "   5. L0_median\n",
      "   6. L0_range\n",
      "   7. L0_skew\n",
      "   8. L0_kurtosis\n",
      "   9. L0_rms\n",
      "  10. L0_var\n",
      "     ... and 206 more features\n",
      "  Null values: 0 (0.00%)\n",
      "  Infinite values: 0\n",
      "  Data completeness: 100.0%\n",
      "        L0_mean  L0_std  L0_min  L0_max  L0_median  label\n",
      "ecg_id                                                   \n",
      "1          -0.0     1.0 -1.8025  6.4619    -0.0964      0\n",
      "2           0.0     1.0 -2.5993  4.9928    -0.3059      0\n",
      "3          -0.0     1.0 -1.3303  6.8463    -0.2824      0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_mean</th>\n",
       "      <th>L0_std</th>\n",
       "      <th>L0_min</th>\n",
       "      <th>L0_max</th>\n",
       "      <th>L0_median</th>\n",
       "      <th>L0_range</th>\n",
       "      <th>L0_skew</th>\n",
       "      <th>L0_kurtosis</th>\n",
       "      <th>L0_rms</th>\n",
       "      <th>L0_var</th>\n",
       "      <th>...</th>\n",
       "      <th>L11_var</th>\n",
       "      <th>L11_q25</th>\n",
       "      <th>L11_q75</th>\n",
       "      <th>L11_iqr</th>\n",
       "      <th>L11_bandpower_total</th>\n",
       "      <th>L11_dominant_freq</th>\n",
       "      <th>L11_bandpower_low</th>\n",
       "      <th>L11_bandpower_mid</th>\n",
       "      <th>L11_bandpower_high</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.705303e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.802458</td>\n",
       "      <td>6.461912</td>\n",
       "      <td>-0.096384</td>\n",
       "      <td>8.264371</td>\n",
       "      <td>2.346514</td>\n",
       "      <td>10.101222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.685034</td>\n",
       "      <td>0.315560</td>\n",
       "      <td>1.000594</td>\n",
       "      <td>0.737153</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.305328</td>\n",
       "      <td>0.378149</td>\n",
       "      <td>0.048817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.237056e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.599301</td>\n",
       "      <td>4.992821</td>\n",
       "      <td>-0.305926</td>\n",
       "      <td>7.592123</td>\n",
       "      <td>1.960769</td>\n",
       "      <td>4.740093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.521839</td>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.637638</td>\n",
       "      <td>1.076266</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.285310</td>\n",
       "      <td>0.485550</td>\n",
       "      <td>0.292536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.973799e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.330285</td>\n",
       "      <td>6.846310</td>\n",
       "      <td>-0.282427</td>\n",
       "      <td>8.176595</td>\n",
       "      <td>3.694111</td>\n",
       "      <td>17.659544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.637029</td>\n",
       "      <td>0.486020</td>\n",
       "      <td>1.123049</td>\n",
       "      <td>0.713340</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.368032</td>\n",
       "      <td>0.154126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.973799e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.156208</td>\n",
       "      <td>3.673837</td>\n",
       "      <td>-0.168618</td>\n",
       "      <td>7.830046</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>3.891946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.597286</td>\n",
       "      <td>0.309020</td>\n",
       "      <td>0.906307</td>\n",
       "      <td>0.773249</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.175284</td>\n",
       "      <td>0.392417</td>\n",
       "      <td>0.194564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.973799e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.182715</td>\n",
       "      <td>5.365592</td>\n",
       "      <td>-0.232521</td>\n",
       "      <td>8.548308</td>\n",
       "      <td>1.974023</td>\n",
       "      <td>6.902985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.515773</td>\n",
       "      <td>0.050236</td>\n",
       "      <td>0.566009</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.213653</td>\n",
       "      <td>0.491305</td>\n",
       "      <td>0.197951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             L0_mean  L0_std    L0_min    L0_max  L0_median  L0_range  \\\n",
       "ecg_id                                                                  \n",
       "1      -1.705303e-16     1.0 -1.802458  6.461912  -0.096384  8.264371   \n",
       "2       9.237056e-17     1.0 -2.599301  4.992821  -0.305926  7.592123   \n",
       "3      -4.973799e-17     1.0 -1.330285  6.846310  -0.282427  8.176595   \n",
       "4       4.973799e-17     1.0 -4.156208  3.673837  -0.168618  7.830046   \n",
       "5      -4.973799e-17     1.0 -3.182715  5.365592  -0.232521  8.548308   \n",
       "\n",
       "         L0_skew  L0_kurtosis  L0_rms  L0_var  ...  L11_var   L11_q25  \\\n",
       "ecg_id                                         ...                      \n",
       "1       2.346514    10.101222     1.0     1.0  ...      1.0 -0.685034   \n",
       "2       1.960769     4.740093     1.0     1.0  ...      1.0 -0.521839   \n",
       "3       3.694111    17.659544     1.0     1.0  ...      1.0 -0.637029   \n",
       "4       0.022307     3.891946     1.0     1.0  ...      1.0 -0.597286   \n",
       "5       1.974023     6.902985     1.0     1.0  ...      1.0 -0.515773   \n",
       "\n",
       "         L11_q75   L11_iqr  L11_bandpower_total  L11_dominant_freq  \\\n",
       "ecg_id                                                               \n",
       "1       0.315560  1.000594             0.737153                3.2   \n",
       "2       0.115798  0.637638             1.076266                0.8   \n",
       "3       0.486020  1.123049             0.713340                3.2   \n",
       "4       0.309020  0.906307             0.773249                1.2   \n",
       "5       0.050236  0.566009             0.913503                3.2   \n",
       "\n",
       "        L11_bandpower_low  L11_bandpower_mid  L11_bandpower_high  label  \n",
       "ecg_id                                                                   \n",
       "1                0.305328           0.378149            0.048817      0  \n",
       "2                0.285310           0.485550            0.292536      0  \n",
       "3                0.181600           0.368032            0.154126      0  \n",
       "4                0.175284           0.392417            0.194564      0  \n",
       "5                0.213653           0.491305            0.197951      0  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Final Dataset Overview ===\n",
    "\n",
    "print(\"Complete Dataset Summary:\")\n",
    "print(f\"Shape: {features_df.shape}\")\n",
    "print(f\"Features: {features_df.shape[1] - 1} (excluding label)\")\n",
    "print(f\"Samples: {features_df.shape[0]}\")\n",
    "print(f\"Memory: {features_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Show column structure\n",
    "feature_cols = [col for col in features_df.columns if col != 'label']\n",
    "print(f\"\\n Feature columns (first 10):\")\n",
    "for i, col in enumerate(feature_cols[:10]):\n",
    "    print(f\"  {i+1:2d}. {col}\")\n",
    "if len(feature_cols) > 10:\n",
    "    print(f\"     ... and {len(feature_cols)-10} more features\")\n",
    "\n",
    "# Data quality check\n",
    "\n",
    "total_values = features_df.shape[0] * features_df.shape[1]\n",
    "null_values = features_df.isnull().sum().sum()\n",
    "inf_values = np.isinf(features_df.select_dtypes(include=[np.number])).sum().sum()\n",
    "\n",
    "print(f\"  Null values: {null_values} ({null_values/total_values*100:.2f}%)\")\n",
    "print(f\"  Infinite values: {inf_values}\")\n",
    "print(f\"  Data completeness: {(1 - null_values/total_values)*100:.1f}%\")\n",
    "\n",
    "# Show sample of data\n",
    "\n",
    "sample_cols = feature_cols[:5] + ['label']\n",
    "sample_data = features_df[sample_cols].head(3)\n",
    "print(sample_data.round(4))\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    output_path = os.path.join(BASE, \"processed_ecg_features.csv\")\n",
    "    features_df.to_csv(output_path)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save dataset: {e}\")\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da4ea220-1495-4c18-a4ba-a612714be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40a19235-efb9-4f1c-a1e2-c25e4503ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (30, 216),  Labels: (30,)\n",
      "Class counts: {0: 21, 1: 9}\n",
      "Train: 24  |  Test: 6\n",
      "Train class counts: {0: 17, 1: 7}\n",
      "Test  class counts: {0: 4, 1: 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = features_df.drop(columns='label')\n",
    "y = features_df['label']\n",
    "\n",
    "print(f\"Features: {X.shape},  Labels: {y.shape}\")\n",
    "print(\"Class counts:\", y.value_counts().to_dict())\n",
    "\n",
    "\n",
    "const_cols = [c for c in X if X[c].nunique() <= 1]\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "    print(f\"Dropped {len(const_cols)} constant columns; {X.shape[1]} features remain.\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}  |  Test: {X_test.shape[0]}\")\n",
    "print(\"Train class counts:\", y_train.value_counts().to_dict())\n",
    "print(\"Test  class counts:\", y_test.value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8779de-3826-4c7d-ae79-74edca281a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "029de59b-3ff7-46eb-bfdf-b31de5520c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 0.11s\n",
      "CV accuracy: 0.9100  Â± 0.1114\n",
      "Fold scores: [0.8  1.   1.   1.   0.75]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_w = dict(zip(np.unique(y_train), class_w))\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators     = 100,\n",
    "    max_depth        = 10,\n",
    "    min_samples_split= 5,\n",
    "    min_samples_leaf = 2,\n",
    "    class_weight     = class_w,\n",
    "    random_state     = 42,\n",
    "    n_jobs           = -1\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "print(f\"Training finished in {time.time() - t0:.2f}s\")\n",
    "cv_scores = cross_val_score(rf, X_train, y_train,\n",
    "                            cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"CV accuracy: {cv_scores.mean():.4f}  Â± {cv_scores.std():.4f}\")\n",
    "print(\"Fold scores:\", cv_scores.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfaa04-032a-4973-a6a0-72621bef4d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4783a-c3a1-4899-abed-3ef4f35a72ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
